{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier for Spam Detection\n",
    "\n",
    "## Instructions\n",
    "\n",
    "Total Points: 10\n",
    "\n",
    "Complete this notebook and submit it. The notebook needs to be a complete project report with \n",
    "\n",
    "* your implementation,\n",
    "* documentation including a short discussion of how your implementation works and your design choices, and\n",
    "* experimental results (e.g., tables and charts with simulation results) with a short discussion of what they mean. \n",
    "\n",
    "Use the provided notebook cells and insert additional code and markdown cells as needed.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "A spam detection agent gets as its percepts text messages and needs to decide if they are spam or not.\n",
    "Create a [naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier) for the \n",
    "[UCI SMS Spam Collection Data Set](https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection) to perform this task.\n",
    "\n",
    "__About the use of libraries:__ The point of this exercise is to learn how a Bayes classifier is built. You may use libraries for tokenizing, stop words and to create a document-term matrix, but you need to implement parameter estimation and prediction yourself.\n",
    "\n",
    "## Create a bag-of-words representation of the text messages [3 Points]\n",
    "\n",
    "The first step is to tokenize the text. Here is an example of how to use the [natural language tool kit (nltk)](https://www.nltk.org/) to create tokens (separate words)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text message: \"ham\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
      "\"\n",
      "tokens: ['ham', 'Go', 'until', 'jurong', 'point', ',', 'crazy..', 'Available', 'only', 'in', 'bugis', 'n', 'great', 'world', 'la', 'e', 'buffet', '...', 'Cine', 'there', 'got', 'amore', 'wat', '...']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# You need to install nltk and then download the tokenizer once.\n",
    "#nltk.download('punkt')\n",
    "\n",
    "file = open(\"smsspamcollection/SMSSpamCollection\", \"r\")\n",
    "\n",
    "sentence = file.readline()\n",
    "print(f\"text message: \\\"{sentence}\\\"\")\n",
    "\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "print(f\"tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with removing frequent words (called [stopwords](https://en.wikipedia.org/wiki/Stop_word)) and very infrequent words so you end up with a reasonable number of words used in the classifier. Maybe you need to remove digits or all non-letter characters. You may also use a stemming algorithm. \n",
    "\n",
    "Convert the tokenized data into a data structure that indicates for each for document what words it contains. The data structure can be a [document-term matrix](https://en.wikipedia.org/wiki/Document-term_matrix) with 0s and 1s, a pandas dataframe or some sparse matrix structure. Note: words, tokens and terms are often used interchangably. Make sure the data structure can be used to split the data into training and test documents (see below).\n",
    "\n",
    "Report the 20 most frequent and the 20 least frequent words in your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description and code goes here!\n",
    "#Just making sure I am correctly processing and reading the lines in the files here\n",
    "file = open(\"smsspamcollection/SMSSpamCollection\", \"r\")\n",
    "\n",
    "sentences = file.readlines()\n",
    "\n",
    "count = 0\n",
    "# Strips the newline character \n",
    "for sentence in sentences:\n",
    "    #print(count)\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    #print(f\"tokens: {tokens}\")\n",
    "    count+=1\n",
    "\n",
    "#Everything looks good, commented out the print statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences: 5574\n",
      "Ham sentences: 4827\n",
      "Ham frequency: 0.8659849300322928\n",
      "Spam sentences: 747\n",
      "Spam frequency: 0.1340150699677072\n",
      "\n",
      "20 least frequent words with their count...\n",
      "\n",
      "[('amor', 1), ('jurong', 1), ('crazy..', 1), ('Tb', 1), ('patent', 1), ('breather', 1), ('grant', 1), ('fulfil', 1), ('xxxmobilemovieclub.com', 1), ('xxxmobilemovieclub', 1), ('n=qjkgighjjgcbl', 1), ('//wap', 1), ('gota', 1), ('macedonia', 1), ('4txt/รฃยบ1.20', 1), ('goals/team', 1), ('poboxox36504w45wq', 1), ('ffffffffff', 1), ('ahhh', 1), ('badli', 1)]\n",
      "\n",
      "20 most frequent words with their count...\n",
      "\n",
      "[('I', 1470), ('...', 772), ('call', 628), ('u', 562), (\"'s\", 435), ('get', 428), ('2', 398), ('go', 395), (\"'m\", 360), ('thi', 325), (\"n't\", 298), ('U', 292), ('come', 287), ('know', 259), ('ur', 259), ('4', 258), ('free', 248), ('gt', 242), ('lt', 242), ('like', 242)]\n",
      "\n",
      "Comparing freq of a few words between ham and spam...\n",
      "Word: free\n",
      "Ham: 57\n",
      "Spam: 191\n",
      "\n",
      "Word: call\n",
      "Ham: 279\n",
      "Spam: 349\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "from nltk.corpus import stopwords \n",
    "\n",
    "#nltk.download('stopwords')\n",
    "stop_words = list(stopwords.words('english')) \n",
    "\n",
    "def makeUnique(l1):\n",
    "    a = set(l1)\n",
    "    uniqueList = list(a)\n",
    "    return uniqueList\n",
    "\n",
    "def updateDict(s, d):\n",
    "    #This function will take in sentence s and update dictionary d\n",
    "    #The sentence is the tokenized line from the file (minus the first word which indicates ham or spam)\n",
    "    #The dictionary is either:\n",
    "    # a) full --meaning that updating the dictionary of all words regardless of spam or ham\n",
    "    # b) ham --updating the dictionary containing sentences of non-spam\n",
    "    # c) spam --updating the dictionary containing sentences of spam\n",
    "    s2 = makeUnique(s) #this function will only keep unique words\n",
    "    ps = PorterStemmer() #used to stem the words\n",
    "    for word in s2:\n",
    "        stemmedWord = ps.stem(word)\n",
    "        if stemmedWord in stop_words: #not including stop words\n",
    "            #print(stemmedWord)\n",
    "            pass\n",
    "        elif stemmedWord in string.punctuation: #not including punctuation\n",
    "            #print(stemmedWord)\n",
    "            pass\n",
    "        elif stemmedWord in d:\n",
    "            d[stemmedWord] +=1 #add 1 to count if already exists\n",
    "        else:\n",
    "            d[stemmedWord] = 1 #else create new key/value pair in the dictionary\n",
    "\n",
    "file = open(\"smsspamcollection/SMSSpamCollection\", \"r\")\n",
    "\n",
    "sentences = file.readlines()\n",
    "full, ham, spam = {}, {}, {}\n",
    "spamCount = 0\n",
    "hamCount = 0\n",
    "total = 0\n",
    "# Strips the newline character \n",
    "for sentence in sentences:\n",
    "    total +=1\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    if tokens[0] == 'ham':\n",
    "        #update ham dict\n",
    "        hamCount+=1\n",
    "        updateDict(tokens[1:], ham)\n",
    "    else:\n",
    "        #update spam dict\n",
    "        spamCount+=1\n",
    "        updateDict(tokens[1:], spam)\n",
    "    \n",
    "    updateDict(tokens[1:], full)\n",
    "\n",
    "\n",
    "#print(ham)\n",
    "sortedHam = sorted(ham.items(), key=lambda item: item[1])\n",
    "sortedHam.reverse()\n",
    "\n",
    "sortedFull = sorted(full.items(), key=lambda item: item[1])\n",
    "mostFreq = []\n",
    "leastFreq = []\n",
    "\n",
    "for item in sortedFull:\n",
    "    leastFreq.append(item)\n",
    "    if len(leastFreq) >= 20:\n",
    "        break\n",
    "\n",
    "sortedFull.reverse() #now want the most frequent words\n",
    "\n",
    "\n",
    "\n",
    "for item in sortedFull:\n",
    "    mostFreq.append(item)\n",
    "    if len(mostFreq) >= 20:\n",
    "        break\n",
    "\n",
    "print(\"Total sentences: {}\".format(total))\n",
    "print(\"Ham sentences: {}\".format(hamCount))\n",
    "print(\"Ham frequency: {}\".format(hamCount/total))\n",
    "print(\"Spam sentences: {}\".format(spamCount))\n",
    "print(\"Spam frequency: {}\".format(spamCount/total))\n",
    "\n",
    "print(\"\\n20 least frequent words with their count...\\n\")\n",
    "print(leastFreq)\n",
    "print(\"\\n20 most frequent words with their count...\\n\")\n",
    "print(mostFreq)\n",
    "\n",
    "\n",
    "print(\"\\nComparing freq of a few words between ham and spam...\")\n",
    "print(\"Word: free\")\n",
    "print(\"Ham: {}\".format(ham['free']))\n",
    "print(\"Spam: {}\".format(spam['free']))\n",
    "\n",
    "print(\"\\nWord: call\")\n",
    "print(\"Ham: {}\".format(ham['call']))\n",
    "print(\"Spam: {}\".format(spam['call']))\n",
    "\n",
    "#Baseline is pretty high with a freq of ham sentences of ~86% if were to just say ham for all messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn parameters [3 Points]\n",
    "\n",
    "Use 80% of the data (called training set; randomly chosen) to learn the parameters of the naive Bayes classifier (prior probabilities and likelihoods). \n",
    "Remember, the naive Bayes classifier calculates:\n",
    "\n",
    "$$P(spam|message) \\propto score_{spam}(message) = P(spam) \\prod_{i=1}^n P(w_i | spam)$$\n",
    "$$P(ham|message) \\propto score_{ham}(message) = P(ham) \\prod_{i=1}^n P(w_i | ham)$$\n",
    "\n",
    "and classifies a message as spam if \n",
    "$$score_{spam}(message) > score_{ham}(message).$$ \n",
    "\n",
    "You therefore need to\n",
    "estimate: \n",
    "\n",
    "* the priors $P(spam)$ and $P(ham)$, and \n",
    "* the likelihoods $P(w_i | spam)$ and $P(w_i | ham)$ for all words\n",
    "\n",
    "from counts obtained from the training data. Use [Laplacian smoothing](https://en.wikipedia.org/wiki/Additive_smoothing) to estimate the\n",
    "likelihoods. This deals with words that have very low count in the ham or spam messages and avoids\n",
    "likelihoods of zero.\n",
    "\n",
    "Report the top 20 words (highest conditional probability) for ham and for spam. These words represent the biggest clues that a message is ham or spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description and code goes here!\n",
    "\n",
    "# Laplacian smoothing: P(word|spam) = # of spam messages that contain the word + 1 / total # of spam messages + # of classes\n",
    "# Need to get 80% of the data to train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#file = open(\"smsspamcollection/SMSSpamCollection\", \"r\")\n",
    "messages = pd.read_fwf(\"smsspamcollection/SMSSpamCollection\")\n",
    "#print(messages.head())\n",
    "y = messages\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# print(X_train)\n",
    "\n",
    "#alright this isn't working so going to go with a different approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "#Playing around to make list unique\n",
    "x = [5,1,1,2,2,3,4,5,4]\n",
    "a = set(x)\n",
    "u = list(a)\n",
    "print(u)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 4460\n",
      "Total: 4460\n",
      "Total ham: 3866\n",
      "Total spam: 594\n",
      "\n",
      "20 most frequent ham words with their count...\n",
      "\n",
      "[('I', 1143), ('...', 606), ('u', 402), (\"'s\", 312), (\"'m\", 291), ('go', 281), ('get', 274), (\"n't\", 227), ('call', 221), ('come', 217), ('2', 202), ('lt', 198), ('gt', 196), ('thi', 188), ('got', 188), ('know', 187), ('like', 185), ('good', 179), (\"'ll\", 174), ('time', 168)]\n",
      "\n",
      "20 most frequent spam words with their count...\n",
      "\n",
      "[('call', 272), ('free', 144), ('txt', 132), ('2', 111), ('text', 109), ('mobil', 98), ('claim', 93), ('stop', 89), ('repli', 88), ('thi', 72), ('4', 71), ('get', 70), ('prize', 67), ('ur', 66), ('To', 65), ('U', 65), ('onli', 59), ('new', 59), ('send', 58), ('tone', 57)]\n"
     ]
    }
   ],
   "source": [
    "#New approach is going to randomly shuffle the list of sentences\n",
    "#Then with the list randomly shuffled, use the first 80% of elements for the training data set\n",
    "#The other 20% will go towards the testing data set\n",
    "import random as rd\n",
    "import math\n",
    "\n",
    "  \n",
    "file = open(\"smsspamcollection/SMSSpamCollection\", \"r\")\n",
    "\n",
    "sentences = file.readlines()\n",
    "rd.shuffle(sentences)\n",
    "\n",
    "# print(len(sentences))\n",
    "# print(len(sentences)*.8)\n",
    "cutoff = math.ceil(len(sentences) *.8)\n",
    "# print(cutoff)\n",
    "f = []\n",
    "train = []\n",
    "test = []\n",
    "trainSize = 0\n",
    "for i in range(cutoff):\n",
    "    train.append(sentences[i])\n",
    "    trainSize +=1\n",
    "\n",
    "for i in range(cutoff, len(sentences)):\n",
    "    test.append(sentences[i])\n",
    "    \n",
    "#print(trainSize/len(sentences))\n",
    "\n",
    "#Now that we have the sentences split into training and testing data...time to learn the params from the training data\n",
    "full, ham, spam = {}, {}, {}\n",
    "spamCount = 0\n",
    "hamCount = 0\n",
    "total = 0\n",
    "for sentence in train:\n",
    "    total +=1\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    if tokens[0] == 'ham':\n",
    "        #update ham dict\n",
    "        hamCount+=1\n",
    "        updateDict(tokens[1:], ham)\n",
    "    else:\n",
    "        #update spam dict\n",
    "        spamCount+=1\n",
    "        updateDict(tokens[1:], spam)\n",
    "    \n",
    "    updateDict(tokens[1:], full)\n",
    "\n",
    "sortedHam = sorted(ham.items(), key=lambda item: item[1])\n",
    "sortedHam.reverse()\n",
    "#print(sortedHam)\n",
    "\n",
    "sortedSpam = sorted(spam.items(), key=lambda item: item[1])\n",
    "sortedSpam.reverse()\n",
    "\n",
    "spamMost = []\n",
    "hamMost = []\n",
    "\n",
    "for item in sortedHam:\n",
    "    hamMost.append(item)\n",
    "    if len(hamMost) >= 20:\n",
    "        break\n",
    "\n",
    "for item in sortedSpam:\n",
    "    spamMost.append(item)\n",
    "    if len(spamMost) >= 20:\n",
    "        break\n",
    "\n",
    "print(\"Total: {}\".format(hamCount+spamCount))\n",
    "print(\"Total: {}\".format(total))\n",
    "print(\"Total ham: {}\".format(hamCount))\n",
    "print(\"Total spam: {}\".format(spamCount))\n",
    "print(\"\\n20 most frequent ham words with their count...\\n\")\n",
    "print(hamMost)\n",
    "print(\"\\n20 most frequent spam words with their count...\\n\")\n",
    "print(spamMost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the classification performance [4 Points] \n",
    "\n",
    "Classify the remaining 20% of the data (test set) and calculate classification accuracy. Accuracy is defined as the proportion of correctly classified test documents.\n",
    "\n",
    "1. How good is your classifier's accuracy compared to a baseline classifier.\n",
    "\n",
    "2. Inspect a few misclassified text messages and discuss why the classification failed.\n",
    "\n",
    "3. Discuss how you deal with words in the test data that you have not seen in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in train: 4460\n",
      "Total ham in train: 3866\n",
      "Total spam in train: 594\n",
      "\n",
      "Now to the testing data results using the baseline of all ham...\n",
      "Total tested: 1114\n",
      "Total correct: 961\n",
      "Accuracy: 0.8626570915619389\n",
      "\n",
      "Now to the testing data results with the trained classifier...\n",
      "Total tested: 1114\n",
      "Total correct: 1042\n",
      "Accuracy: 0.9353680430879713\n",
      "\n",
      "My classifier was 0.07271095152603235 better than the baseline in classifying ham v. spam\n"
     ]
    }
   ],
   "source": [
    "# Description, code and discussion goes here!\n",
    "print(\"Total in train: {}\".format(hamCount+spamCount))\n",
    "print(\"Total ham in train: {}\".format(hamCount))\n",
    "print(\"Total spam in train: {}\".format(spamCount))\n",
    "def classifier(sortHam, hamCount, sortSpam, spamCount, s):\n",
    "    ps = PorterStemmer() #used to stem the words\n",
    "    spamOrHam = 0\n",
    "    for word in s:\n",
    "        stemmedWord = ps.stem(word)\n",
    "        if stemmedWord in stop_words: #not including stop words\n",
    "            #print(stemmedWord)\n",
    "            pass\n",
    "        elif stemmedWord in string.punctuation: #not including punctuation\n",
    "            #print(stemmedWord)\n",
    "            pass\n",
    "        else:\n",
    "            #print(stemmedWord)\n",
    "            if stemmedWord in sortHam:\n",
    "                #print(sortHam[stemmedWord])\n",
    "                spamOrHam += sortHam[stemmedWord] + 1 / hamCount + 2\n",
    "            else:\n",
    "                spamOrHam += 1 / hamCount + 2\n",
    "                #print(stemmedWord)\n",
    "            \n",
    "            if stemmedWord in sortSpam:\n",
    "                spamOrHam -= sortSpam[stemmedWord] + 1 / spamCount + 2\n",
    "            else:\n",
    "                spamOrHam -= 1 / spamCount + 2\n",
    "                #print(stemmedWord)\n",
    "    \n",
    "    #print(spamOrHam)\n",
    "    if spamOrHam >= 0:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        return \"spam\"\n",
    "\n",
    "\n",
    "correct = 0\n",
    "testTotal = 0\n",
    "hammers = 0\n",
    "missed = []\n",
    "for sentence in test:\n",
    "    testTotal +=1\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    #print(tokens)\n",
    "    if tokens[0] == 'ham':\n",
    "        hammers +=1\n",
    "        ans = classifier(ham, hamCount, spam, spamCount, tokens[1:])\n",
    "        if ans == 'ham':\n",
    "            correct +=1\n",
    "        else:\n",
    "            missed.append(tokens)\n",
    "            pass\n",
    "            #print(\"missed ham...\")\n",
    "            #print(tokens)\n",
    "    else:\n",
    "        ans = classifier(ham, hamCount, spam, spamCount, tokens[1:])\n",
    "        if ans == 'spam':\n",
    "            correct +=1\n",
    "        else:\n",
    "            missed.append(tokens)\n",
    "            pass\n",
    "            #print(\"missed spam...\")\n",
    "            #print(tokens)\n",
    "\n",
    "\n",
    "print(\"\\nNow to the testing data results using the baseline of all ham...\")\n",
    "print(\"Total tested: {}\".format(testTotal))\n",
    "print(\"Total correct: {}\".format(hammers))\n",
    "print(\"Accuracy: {}\".format(hammers/testTotal))\n",
    "\n",
    "print(\"\\nNow to the testing data results with the trained classifier...\")\n",
    "print(\"Total tested: {}\".format(testTotal))\n",
    "print(\"Total correct: {}\".format(correct))\n",
    "print(\"Accuracy: {}\".format(correct/testTotal))\n",
    "\n",
    "diff = (correct/testTotal) - (hammers/testTotal)\n",
    "print(\"\\nMy classifier was {} better than the baseline in classifying ham v. spam\".format(diff))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Questions\n",
    "\n",
    "1. How good is your classifier's accuracy compared to a baseline classifier.\n",
    "     * My classifier is ~7.27% more accurate than the baseline classifier (saying all the messages are ham) with an accuracy of 93.54% vs. the baseline's accuracy of 86.27%.\n",
    "\n",
    "\n",
    "2. Inspect a few misclassified text messages and discuss why the classification failed.\n",
    "    * I added the misclassified text messages to a list and printed them out below. Two things stand out to me in inspecting these misclassified messages. \n",
    "    * First, a lot of the messages missed contain punctuation and numbers. I strip the punctuation from the messages so it is ignored in determining whether it is ham or spam. Ignoring the punctuation may have negatively impacted the classifier as it just did not take it into account. Additionally, the missed messages contain a lot of numbers in them. My classifier searches for exact matches in determining their conditional probability. Maybe if I set two variables that correspond to a string of numbers within a certain range and then any string of numbers outside of that range. This way, all the numbers could still be accounted for in terms of their length but the messages would not need to match up each digit in the string of numbers.\n",
    "    * Second, the majority of the misclassified text messages are spam but were classified as ham. While the punctuation and numbers reasoning mentioned above may lead to this, I also believe having a larger and/or more balanced training data set would also help. Of the 4,460 messages in the training set, only 594 were spam while there were 3,866 ham messages. Having a larger and more balanced data set might help in building a more accurate classifier.\n",
    "    \n",
    "    \n",
    "3. Discuss how you deal with words in the test data that you have not seen in the training data.\n",
    "    * I deal with words in the test data that I have not seen in the training data by following the method of Laplacian Smoothing. So in general it follows this formula where the # of classes is 2 (ham vs. spam): P(word|spam) = # of spam messages that contain the word + 1 / total # of spam messages + # of classes. However, when the word does not appear in the class, then the conditionally probability simplifies to P(word|spam) = 1 / total # of spam messages + 2. This is used in order to produce a conditional probability for words not discovered in the training data while ensuring that there are no division errors (e.g. divide by 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now time to look at the misclassified messages...\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Not', 'heard', 'from', 'U4', 'a', 'while', '.', 'Call', 'me', 'now', 'am', 'here', 'all', 'night', 'with', 'just', 'my', 'knickers', 'on', '.', 'Make', 'me', 'beg', 'for', 'it', 'like', 'U', 'did', 'last', 'time', '01223585236', 'XX', 'Luv', 'Nikiyu4.net']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Hello', 'from', 'Orange', '.', 'For', '1', 'month', \"'s\", 'free', 'access', 'to', 'games', ',', 'news', 'and', 'sport', ',', 'plus', '10', 'free', 'texts', 'and', '20', 'photo', 'messages', ',', 'reply', 'YES', '.', 'Terms', 'apply', ':', 'www.orange.co.uk/ow']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Dont', 'forget', 'you', 'can', 'place', 'as', 'many', 'FREE', 'Requests', 'with', '1stchoice.co.uk', 'as', 'you', 'wish', '.', 'For', 'more', 'Information', 'call', '08707808226', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['For', 'ur', 'chance', 'to', 'win', 'a', 'รยฃ250', 'cash', 'every', 'wk', 'TXT', ':', 'ACTION', 'to', '80608', '.', 'T', \"'s\", '&', 'C', \"'s\", 'www.movietrivia.tv', 'custcare', '08712405022', ',', '1x150p/wk', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Latest', 'News', '!', 'Police', 'station', 'toilet', 'stolen', ',', 'cops', 'have', 'nothing', 'to', 'go', 'on', '!']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['You', 'have', 'won', 'a', 'guaranteed', '32000', 'award', 'or', 'maybe', 'even', 'รยฃ1000', 'cash', 'to', 'claim', 'ur', 'award', 'call', 'free', 'on', '0800', '...', '..', '(', '18+', ')', '.', 'Its', 'a', 'legitimat', 'efreefone', 'number', 'wat', 'do', 'u', 'think', '?', '?', '?']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['<', 'Forwarded', 'from', '21870000', '>', 'Hi', '-', 'this', 'is', 'your', 'Mailbox', 'Messaging', 'SMS', 'alert', '.', 'You', 'have', '4', 'messages', '.', 'You', 'have', '21', 'matches', '.', 'Please', 'call', 'back', 'on', '09056242159', 'to', 'retrieve', 'your', 'messages', 'and', 'matches']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Ringtone', 'Club', ':', 'Get', 'the', 'UK', 'singles', 'chart', 'on', 'your', 'mobile', 'each', 'week', 'and', 'choose', 'any', 'top', 'quality', 'ringtone', '!', 'This', 'message', 'is', 'free', 'of', 'charge', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Update_Now', '-', '12Mths', 'Half', 'Price', 'Orange', 'line', 'rental', ':', '400mins', '...', 'Call', 'MobileUpd8', 'on', '08000839402', 'or', 'call2optout=J5Q']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Check', 'Out', 'Choose', 'Your', 'Babe', 'Videos', '@', 'sms.shsex.netUN', 'fgkslpoPW', 'fgkslpo']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['For', 'taking', 'part', 'in', 'our', 'mobile', 'survey', 'yesterday', '!', 'You', 'can', 'now', 'have', '500', 'texts', '2', 'use', 'however', 'you', 'wish', '.', '2', 'get', 'txts', 'just', 'send', 'TXT', 'to', '80160', 'T', '&', 'C', 'www.txt43.com', '1.50p']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Our', 'dating', 'service', 'has', 'been', 'asked', '2', 'contact', 'U', 'by', 'someone', 'shy', '!', 'CALL', '09058091870', 'NOW', 'all', 'will', 'be', 'revealed', '.', 'POBox84', ',', 'M26', '3UZ', '150p']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Bored', 'housewives', '!', 'Chat', 'n', 'date', 'now', '!', '0871750.77.11', '!', 'BT-national', 'rate', '10p/min', 'only', 'from', 'landlines', '!']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Someone', 'U', 'know', 'has', 'asked', 'our', 'dating', 'service', '2', 'contact', 'you', '!', 'Cant', 'Guess', 'who', '?', 'CALL', '09058091854', 'NOW', 'all', 'will', 'be', 'revealed', '.', 'PO', 'BOX385', 'M6', '6WU']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Refused', 'a', 'loan', '?', 'Secured', 'or', 'Unsecured', '?', 'Ca', \"n't\", 'get', 'credit', '?', 'Call', 'free', 'now', '0800', '195', '6669', 'or', 'text', 'back', \"'help\", \"'\", '&', 'we', 'will', '!']\n",
      "\n",
      "Missed a ham message containing:\n",
      "['Raviyog', 'Peripherals', 'bhayandar', 'east']\n",
      "\n",
      "Missed a ham message containing:\n",
      "['Which', 'channel', ':', '-', ')', ':', '-', ')', ':', ')', ':', '-', ')', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['RT-KIng', 'Pro', 'Video', 'Club', '>', '>', 'Need', 'help', '?', 'info', '@', 'ringtoneking.co.uk', 'or', 'call', '08701237397', 'You', 'must', 'be', '16+', 'Club', 'credits', 'redeemable', 'at', 'www.ringtoneking.co.uk', '!', 'Enjoy', '!']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Hello', '.', 'We', 'need', 'some', 'posh', 'birds', 'and', 'chaps', 'to', 'user', 'trial', 'prods', 'for', 'champneys', '.', 'Can', 'i', 'put', 'you', 'down', '?', 'I', 'need', 'your', 'address', 'and', 'dob', 'asap', '.', 'Ta', 'r']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['As', 'a', 'valued', 'customer', ',', 'I', 'am', 'pleased', 'to', 'advise', 'you', 'that', 'following', 'recent', 'review', 'of', 'your', 'Mob', 'No', '.', 'you', 'are', 'awarded', 'with', 'a', 'รยฃ1500', 'Bonus', 'Prize', ',', 'call', '09066368470']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['FREE', 'RING', 'TONE', 'just', 'text', '``', 'POLYS', \"''\", 'to', '87131', '.', 'Then', 'every', 'week', 'get', 'a', 'new', 'tone', '.', '0870737910216yrs', 'only', 'รยฃ1.50/wk', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['FREE2DAY', 'sexy', 'St', 'George', \"'s\", 'Day', 'pic', 'of', 'Jordan', '!', 'Txt', 'PIC', 'to', '89080', 'dont', 'miss', 'out', ',', 'then', 'every', 'wk', 'a', 'saucy', 'celeb', '!', '4', 'more', 'pics', 'c', 'PocketBabe.co.uk', '0870241182716', 'รยฃ3/wk']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['FREE', 'for', '1st', 'week', '!', 'No1', 'Nokia', 'tone', '4', 'ur', 'mob', 'every', 'week', 'just', 'txt', 'NOKIA', 'to', '87077', 'Get', 'txting', 'and', 'tell', 'ur', 'mates', '.', 'zed', 'POBox', '36504', 'W45WQ', 'norm150p/tone', '16+']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Our', 'records', 'indicate', 'u', 'maybe', 'entitled', 'to', '5000', 'pounds', 'in', 'compensation', 'for', 'the', 'Accident', 'you', 'had', '.', 'To', 'claim', '4', 'free', 'reply', 'with', 'CLAIM', 'to', 'this', 'msg', '.', '2', 'stop', 'txt', 'STOP']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Hello', 'darling', 'how', 'are', 'you', 'today', '?', 'I', 'would', 'love', 'to', 'have', 'a', 'chat', ',', 'why', 'dont', 'you', 'tell', 'me', 'what', 'you', 'look', 'like', 'and', 'what', 'you', 'are', 'in', 'to', 'sexy', '?']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Natalie', '(', '20/F', ')', 'is', 'inviting', 'you', 'to', 'be', 'her', 'friend', '.', 'Reply', 'YES-165', 'or', 'NO-165', 'See', 'her', ':', 'www.SMS.ac/u/natalie2k9', 'STOP', '?', 'Send', 'STOP', 'FRND', 'to', '62468']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Do', 'you', 'ever', 'notice', 'that', 'when', 'you', \"'re\", 'driving', ',', 'anyone', 'going', 'slower', 'than', 'you', 'is', 'an', 'idiot', 'and', 'everyone', 'driving', 'faster', 'than', 'you', 'is', 'a', 'maniac', '?']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['SMS', '.', 'ac', 'JSco', ':', 'Energy', 'is', 'high', ',', 'but', 'u', 'may', 'not', 'know', 'where', '2channel', 'it', '.', '2day', 'ur', 'leadership', 'skills', 'r', 'strong', '.', 'Psychic', '?', 'Reply', 'ANS', 'w/question', '.', 'End', '?', 'Reply', 'END', 'JSCO']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Call', 'Germany', 'for', 'only', '1', 'pence', 'per', 'minute', '!', 'Call', 'from', 'a', 'fixed', 'line', 'via', 'access', 'number', '0844', '861', '85', '85', '.', 'No', 'prepayment', '.', 'Direct', 'access', '!']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Sorry', 'I', 'missed', 'your', 'call', 'let', \"'s\", 'talk', 'when', 'you', 'have', 'the', 'time', '.', 'I', \"'m\", 'on', '07090201529']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['You', 'are', 'now', 'unsubscribed', 'all', 'services', '.', 'Get', 'tons', 'of', 'sexy', 'babes', 'or', 'hunks', 'straight', 'to', 'your', 'phone', '!', 'go', 'to', 'http', ':', '//gotbabes.co.uk', '.', 'No', 'subscriptions', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['TBS/PERSOLVO', '.', 'been', 'chasing', 'us', 'since', 'Sept', 'forรยฃ38', 'definitely', 'not', 'paying', 'now', 'thanks', 'to', 'your', 'information', '.', 'We', 'will', 'ignore', 'them', '.', 'Kath', '.', 'Manchester', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['22', 'days', 'to', 'kick', 'off', '!', 'For', 'Euro2004', 'U', 'will', 'be', 'kept', 'up', 'to', 'date', 'with', 'the', 'latest', 'news', 'and', 'results', 'daily', '.', 'To', 'be', 'removed', 'send', 'GET', 'TXT', 'STOP', 'to', '83222']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Are', 'you', 'unique', 'enough', '?', 'Find', 'out', 'from', '30th', 'August', '.', 'www.areyouunique.co.uk']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['2p', 'per', 'min', 'to', 'call', 'Germany', '08448350055', 'from', 'your', 'BT', 'line', '.', 'Just', '2p', 'per', 'min', '.', 'Check', 'PlanetTalkInstant.com', 'for', 'info', '&', 'T', \"'s\", '&', 'C', \"'s\", '.', 'Text', 'stop', 'to', 'opt', 'out']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Congratulations', 'U', 'can', 'claim', '2', 'VIP', 'row', 'A', 'Tickets', '2', 'C', 'Blu', 'in', 'concert', 'in', 'November', 'or', 'Blu', 'gift', 'guaranteed', 'Call', '09061104276', 'to', 'claim', 'TS', '&', 'Cs', 'www.smsco.net', 'costรยฃ3.75max']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['thesmszone.com', 'lets', 'you', 'send', 'free', 'anonymous', 'and', 'masked', 'messages..im', 'sending', 'this', 'message', 'from', 'there..do', 'you', 'see', 'the', 'potential', 'for', 'abuse', '?', '?', '?']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Congratulations', '-', 'Thanks', 'to', 'a', 'good', 'friend', 'U', 'have', 'WON', 'the', 'รยฃ2,000', 'Xmas', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'just', 'call', '08712103738', 'NOW', '!', 'Only', '10p', 'per', 'minute', '.', 'BT-national-rate']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['LookAtMe', '!', ':', 'Thanks', 'for', 'your', 'purchase', 'of', 'a', 'video', 'clip', 'from', 'LookAtMe', '!', ',', 'you', \"'ve\", 'been', 'charged', '35p', '.', 'Think', 'you', 'can', 'do', 'better', '?', 'Why', 'not', 'send', 'a', 'video', 'in', 'a', 'MMSto', '32323', '.']\n",
      "\n",
      "Missed a ham message containing:\n",
      "['Studying', '.', 'But', 'i.ll', 'be', 'free', 'next', 'weekend', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['complimentary', '4', 'STAR', 'Ibiza', 'Holiday', 'or', 'รยฃ10,000', 'cash', 'needs', 'your', 'URGENT', 'collection', '.', '09066364349', 'NOW', 'from', 'Landline', 'not', 'to', 'lose', 'out', '!', 'Box434SK38WP150PPM18+']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Ur', 'cash-balance', 'is', 'currently', '500', 'pounds', '-', 'to', 'maximize', 'ur', 'cash-in', 'now', 'send', 'GO', 'to', '86688', 'only', '150p/meg', '.', 'CC', ':', '08718720201', 'HG/Suite342/2lands', 'Row/W1j6HL']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['We', 'have', 'new', 'local', 'dates', 'in', 'your', 'area', '-', 'Lots', 'of', 'new', 'people', 'registered', 'in', 'YOUR', 'AREA', '.', 'Reply', 'DATE', 'to', 'start', 'now', '!', '18', 'only', 'www.flirtparty.us', 'REPLYS150']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Think', 'ur', 'smart', '?', 'Win', 'รยฃ200', 'this', 'week', 'in', 'our', 'weekly', 'quiz', ',', 'text', 'PLAY', 'to', '85222', 'now', '!', 'T', '&', 'Cs', 'WinnersClub', 'PO', 'BOX', '84', ',', 'M26', '3UZ', '.', '16+', '.', 'GBP1.50/week']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Hi', 'ya', 'babe', 'x', 'u', '4goten', 'bout', 'me', '?', \"'\", 'scammers', 'getting', 'smart..Though', 'this', 'is', 'a', 'regular', 'vodafone', 'no', ',', 'if', 'you', 'respond', 'you', 'get', 'further', 'prem', 'rate', 'msg/subscription', '.', 'Other', 'nos', 'used', 'also', '.', 'Beware', '!']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Congrats', '!', '1', 'year', 'special', 'cinema', 'pass', 'for', '2', 'is', 'yours', '.', 'call', '09061209465', 'now', '!', 'C', 'Suprman', 'V', ',', 'Matrix3', ',', 'StarWars3', ',', 'etc', 'all', '4', 'FREE', '!', 'bx420-ip4-5we', '.', '150pm', '.', 'Dont', 'miss', 'out', '!']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['England', 'v', 'Macedonia', '-', 'dont', 'miss', 'the', 'goals/team', 'news', '.', 'Txt', 'ur', 'national', 'team', 'to', '87077', 'eg', 'ENGLAND', 'to', '87077', 'Try', ':', 'WALES', ',', 'SCOTLAND', '4txt/รยบ1.20', 'POBOXox36504W45WQ', '16+']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['If', 'you', 'do', \"n't\", ',', 'your', 'prize', 'will', 'go', 'to', 'another', 'customer', '.', 'T', '&', 'C', 'at', 'www.t-c.biz', '18+', '150p/min', 'Polo', 'Ltd', 'Suite', '373', 'London', 'W1J', '6HL', 'Please', 'call', 'back', 'if', 'busy']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Bloomberg', '-Message', 'center', '+447797706009', 'Why', 'wait', '?', 'Apply', 'for', 'your', 'future', 'http', ':', '//careers', '.', 'bloomberg.com']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['FreeMsg', 'Hey', 'there', 'darling', 'it', \"'s\", 'been', '3', 'week', \"'s\", 'now', 'and', 'no', 'word', 'back', '!', 'I', \"'d\", 'like', 'some', 'fun', 'you', 'up', 'for', 'it', 'still', '?', 'Tb', 'ok', '!', 'XxX', 'std', 'chgs', 'to', 'send', ',', 'รยฃ1.50', 'to', 'rcv']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Free', 'entry', 'in', '2', 'a', 'wkly', 'comp', 'to', 'win', 'FA', 'Cup', 'final', 'tkts', '21st', 'May', '2005', '.', 'Text', 'FA', 'to', '87121', 'to', 'receive', 'entry', 'question', '(', 'std', 'txt', 'rate', ')', 'T', '&', 'C', \"'s\", 'apply', '08452810075over18', \"'s\"]\n",
      "\n",
      "Missed a ham message containing:\n",
      "['Hey', 'now', 'am', 'free', 'you', 'can', 'call', 'me', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Am', 'new', '2', 'club', '&', 'dont', 'fink', 'we', 'met', 'yet', 'Will', 'B', 'gr8', '2', 'C', 'U', 'Please', 'leave', 'msg', '2day', 'wiv', 'ur', 'area', '09099726553', 'reply', 'promised', 'CARLIE', 'x', 'Callsรยฃ1/minMobsmore', 'LKPOBOX177HP51FL']\n",
      "\n",
      "Missed a ham message containing:\n",
      "['Mostly', 'sports', 'type..lyk', 'footbl', ',', 'crckt..']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Text', '&', 'meet', 'someone', 'sexy', 'today', '.', 'U', 'can', 'find', 'a', 'date', 'or', 'even', 'flirt', 'its', 'up', 'to', 'U', '.', 'Join', '4', 'just', '10p', '.', 'REPLY', 'with', 'NAME', '&', 'AGE', 'eg', 'Sam', '25', '.', '18', '-msg', 'recd', '@', 'thirtyeight', 'pence']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['You', 'have', 'won', 'a', 'Nokia', '7250i', '.', 'This', 'is', 'what', 'you', 'get', 'when', 'you', 'win', 'our', 'FREE', 'auction', '.', 'To', 'take', 'part', 'send', 'Nokia', 'to', '86021', 'now', '.', 'HG/Suite342/2Lands', 'Row/W1JHL', '16+']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['As', 'a', 'SIM', 'subscriber', ',', 'you', 'are', 'selected', 'to', 'receive', 'a', 'Bonus', '!', 'Get', 'it', 'delivered', 'to', 'your', 'door', ',', 'Txt', 'the', 'word', 'OK', 'to', 'No', ':', '88600', 'to', 'claim', '.', '150p/msg', ',', 'EXP', '.', '30Apr']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Hi', '07734396839', 'IBH', 'Customer', 'Loyalty', 'Offer', ':', 'The', 'NEW', 'NOKIA6600', 'Mobile', 'from', 'ONLY', 'รยฃ10', 'at', 'TXTAUCTION', '!', 'Txt', 'word', ':', 'START', 'to', 'No:81151', '&', 'get', 'Yours', 'Now', '!', '4T', '&']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Loan', 'for', 'any', 'purpose', 'รยฃ500', '-', 'รยฃ75,000', '.', 'Homeowners', '+', 'Tenants', 'welcome', '.', 'Have', 'you', 'been', 'previously', 'refused', '?', 'We', 'can', 'still', 'help', '.', 'Call', 'Free', '0800', '1956669', 'or', 'text', 'back', \"'help\", \"'\"]\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Congratulations', '!', 'Thanks', 'to', 'a', 'good', 'friend', 'U', 'have', 'WON', 'the', 'รยฃ2,000', 'Xmas', 'prize', '.', '2', 'claim', 'is', 'easy', ',', 'just', 'call', '08718726971', 'NOW', '!', 'Only', '10p', 'per', 'minute', '.', 'BT-national-rate', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['You', 'are', 'being', 'ripped', 'off', '!', 'Get', 'your', 'mobile', 'content', 'from', 'www.clubmoby.com', 'call', '08717509990', 'poly/true/Pix/Ringtones/Games', 'six', 'downloads', 'for', 'only', '3']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Send', 'a', 'logo', '2', 'ur', 'lover', '-', '2', 'names', 'joined', 'by', 'a', 'heart', '.', 'Txt', 'LOVE', 'NAME1', 'NAME2', 'MOBNO', 'eg', 'LOVE', 'ADAM', 'EVE', '07123456789', 'to', '87077', 'Yahoo', '!', 'POBox36504W45WQ', 'TxtNO', '4', 'no', 'ads', '150p', '.']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Loans', 'for', 'any', 'purpose', 'even', 'if', 'you', 'have', 'Bad', 'Credit', '!', 'Tenants', 'Welcome', '.', 'Call', 'NoWorriesLoans.com', 'on', '08717111821']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['cmon', 'babe', ',', 'make', 'me', 'horny', ',', '*turn*', 'me', 'on', '!', 'Txt', 'me', 'your', 'fantasy', 'now', 'babe', '-', ')', 'Im', 'hot', ',', 'sticky', 'and', 'need', 'you', 'now', '.', 'All', 'replies', 'cost', 'รยฃ1.50', '.', '2', 'cancel', 'send', 'STOP']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['SMS', 'AUCTION', '-', 'A', 'BRAND', 'NEW', 'Nokia', '7250', 'is', 'up', '4', 'auction', 'today', '!', 'Auction', 'is', 'FREE', '2', 'join', '&', 'take', 'part', '!', 'Txt', 'NOKIA', 'to', '86021', 'now', '!', 'HG/Suite342/2Lands', 'Row/W1J6HL']\n",
      "\n",
      "Missed a ham message containing:\n",
      "['Aight', ',', 'can', 'you', 'text', 'me', 'the', 'address', '?']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['CLAIRE', 'here', 'am', 'havin', 'borin', 'time', '&', 'am', 'now', 'alone', 'U', 'wan', 'na', 'cum', 'over', '2nite', '?', 'Chat', 'now', '09099725823', 'hope', '2', 'C', 'U', 'Luv', 'CLAIRE', 'xx', 'Callsรยฃ1/minmoremobsEMSPOBox45PO139WA']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Sorry', '!', 'U', 'can', 'not', 'unsubscribe', 'yet', '.', 'THE', 'MOB', 'offer', 'package', 'has', 'a', 'min', 'term', 'of', '54', 'weeks', '>', 'pls', 'resubmit', 'request', 'after', 'expiry', '.', 'Reply', 'THEMOB', 'HELP', '4', 'more', 'info']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['How', 'about', 'getting', 'in', 'touch', 'with', 'folks', 'waiting', 'for', 'company', '?', 'Just', 'txt', 'back', 'your', 'NAME', 'and', 'AGE', 'to', 'opt', 'in', '!', 'Enjoy', 'the', 'community', '(', '150p/SMS', ')']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Will', 'u', 'meet', 'ur', 'dream', 'partner', 'soon', '?', 'Is', 'ur', 'career', 'off', '2', 'a', 'flyng', 'start', '?', '2', 'find', 'out', 'free', ',', 'txt', 'HORO', 'followed', 'by', 'ur', 'star', 'sign', ',', 'e.', 'g.', 'HORO', 'ARIES']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['LIFE', 'has', 'never', 'been', 'this', 'much', 'fun', 'and', 'great', 'until', 'you', 'came', 'in', '.', 'You', 'made', 'it', 'truly', 'special', 'for', 'me', '.', 'I', 'wo', \"n't\", 'forget', 'you', '!', 'enjoy', '@', 'one', 'gbp/sms']\n",
      "\n",
      "Missed a spam message containing:\n",
      "['Call', '09094100151', 'to', 'use', 'ur', 'mins', '!', 'Calls', 'cast', '10p/min', '(', 'mob', 'vary', ')', '.', 'Service', 'provided', 'by', 'AOM', ',', 'just', 'GBP5/month', '.', 'AOM', 'Box61', ',', 'M60', '1ER', 'until', 'u', 'stop', '.', 'Ages', '18+', 'only', '!']\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nNow time to look at the misclassified messages...\")\n",
    "for miss in missed:\n",
    "    print(\"\\nMissed a {} message containing:\".format(miss[0]))\n",
    "    print(miss[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus task [+1 Point]\n",
    "\n",
    "Describe how you could improve the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Improvement to the Classifier\n",
    "\n",
    "* Instead of dividing by total # of messages in the class, divide by the total # of message of both classes in calculating the conditional probability (implemented below)\n",
    "* Including punctuation in the classifier\n",
    "* Taking the order of the words/numbers/punctuation into account\n",
    "* Looking if there is a dollar amount...maybe make it have to be over a certain amount of money (spam requesting money to be sent)\n",
    "* Associating strings of numbers to variables that account for numbers within certain ranges. This way, you would not need to directly match the digits of a string of numbers, but rather just looking at its overall length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total in train: 4460\n",
      "Total ham in train: 3866\n",
      "Total spam in train: 594\n",
      "\n",
      "Now to the testing data results using the baseline of all ham...\n",
      "Total tested: 1114\n",
      "Total correct: 961\n",
      "Accuracy: 0.8626570915619389\n",
      "\n",
      "Now to the testing data results with the trained classifier...\n",
      "Total tested: 1114\n",
      "Total correct: 1040\n",
      "Accuracy: 0.933572710951526\n"
     ]
    }
   ],
   "source": [
    "# Code goes here!\n",
    "\n",
    "print(\"Total in train: {}\".format(hamCount+spamCount))\n",
    "print(\"Total ham in train: {}\".format(hamCount))\n",
    "print(\"Total spam in train: {}\".format(spamCount))\n",
    "def classifier(sortHam, hamCount, sortSpam, spamCount, s):\n",
    "    ps = PorterStemmer() #used to stem the words\n",
    "    totalC = hamCount + spamCount\n",
    "    spamOrHam = 0\n",
    "    for word in s:\n",
    "        stemmedWord = ps.stem(word)\n",
    "        if stemmedWord in stop_words: #not including stop words\n",
    "            #print(stemmedWord)\n",
    "            pass\n",
    "        elif stemmedWord in string.punctuation: #not including punctuation\n",
    "            #print(stemmedWord)\n",
    "            pass\n",
    "        else:\n",
    "            if stemmedWord in sortHam:\n",
    "                spamOrHam += sortHam[stemmedWord] + 1 / totalC + 2\n",
    "            else:\n",
    "                spamOrHam += 1 / totalC + 2\n",
    "            \n",
    "            if stemmedWord in sortSpam:\n",
    "                spamOrHam -= sortSpam[stemmedWord] + 1 / totalC + 2\n",
    "            else:\n",
    "                spamOrHam -= 1 / totalC + 2\n",
    "    \n",
    "    #print(spamOrHam)\n",
    "    if spamOrHam >= 0:\n",
    "        return \"ham\"\n",
    "    else:\n",
    "        return \"spam\"\n",
    "\n",
    "\n",
    "correct = 0\n",
    "testTotal = 0\n",
    "hammers = 0\n",
    "for sentence in test:\n",
    "    testTotal +=1\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    if tokens[0] == 'ham':\n",
    "        hammers +=1\n",
    "        ans = classifier(ham, hamCount, spam, spamCount, tokens[1:])\n",
    "        if ans == 'ham':\n",
    "            correct +=1\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"missed ham...\")\n",
    "            #print(tokens)\n",
    "    else:\n",
    "        ans = classifier(ham, hamCount, spam, spamCount, tokens[1:])\n",
    "        if ans == 'spam':\n",
    "            correct +=1\n",
    "        else:\n",
    "            pass\n",
    "            #print(\"missed spam...\")\n",
    "            #print(tokens)\n",
    "\n",
    "print(\"\\nNow to the testing data results using the baseline of all ham...\")\n",
    "print(\"Total tested: {}\".format(testTotal))\n",
    "print(\"Total correct: {}\".format(hammers))\n",
    "print(\"Accuracy: {}\".format(hammers/testTotal))\n",
    "\n",
    "print(\"\\nNow to the testing data results with the trained classifier...\")\n",
    "print(\"Total tested: {}\".format(testTotal))\n",
    "print(\"Total correct: {}\".format(correct))\n",
    "print(\"Accuracy: {}\".format(correct/testTotal))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that my first idea of dividing by the total # of message of both classes in calculating the conditional probability rather dividing by the total # of messages in the specific class did not help the classifier. This made the classifier slightly less accurate as the original classifier was able to classify 1,042 messages. On the other hand, this change led to the new classifier only getting 1,040 messages correct. While it missed 2 more messages than the classifier implemented earlier, this approach still produced a classifier that is ~7% better than the baseline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
